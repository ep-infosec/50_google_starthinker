{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CM360 Data Transfer To Bigquery",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10001"
      },
      "source": [
        "#CM360 Data Transfer To Bigquery\n",
        "Move data from a DT bucket into a BigQuery table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10002"
      },
      "source": [
        "#License\n",
        "\n",
        "Copyright 2020 Google LLC,\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "  https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10003"
      },
      "source": [
        "#Disclaimer\n",
        "This is not an officially supported Google product. It is a reference implementation. There is absolutely NO WARRANTY provided for using this code. The code is Apache Licensed and CAN BE fully modified, white labeled, and disassembled by your team.\n",
        "\n",
        "This code generated (see starthinker/scripts for possible source):\n",
        "  - **Command**: \"python starthinker_ui/manage.py colab\"\n",
        "  - **Command**: \"python starthinker/tools/colab.py [JSON RECIPE]\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10004"
      },
      "source": [
        "#1. Install Dependencies\n",
        "First install the libraries needed to execute recipes, this only needs to be done once, then click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "397f08b10005"
      },
      "source": [
        "!pip install git+https://github.com/google/starthinker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10006"
      },
      "source": [
        "#2. Set Configuration\n",
        "\n",
        "This code is required to initialize the project. Fill in required fields and press play.\n",
        "\n",
        "1. If the recipe uses a Google Cloud Project:\n",
        "  - Set the configuration **project** value to the project identifier from [these instructions](https://github.com/google/starthinker/blob/master/tutorials/cloud_project.md).\n",
        "\n",
        "1. If the recipe has **auth** set to **user**:\n",
        "  - If you have user credentials:\n",
        "    - Set the configuration **user** value to your user credentials JSON.\n",
        "  - If you DO NOT have user credentials:\n",
        "    - Set the configuration **client** value to [downloaded client credentials](https://github.com/google/starthinker/blob/master/tutorials/cloud_client_installed.md).\n",
        "\n",
        "1. If the recipe has **auth** set to **service**:\n",
        "  - Set the configuration **service** value to [downloaded service credentials](https://github.com/google/starthinker/blob/master/tutorials/cloud_service.md).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "397f08b10007"
      },
      "source": [
        "from starthinker.util.configuration import Configuration\n",
        "\n",
        "\n",
        "CONFIG = Configuration(\n",
        "  project=\"\",\n",
        "  client={},\n",
        "  service={},\n",
        "  user=\"/content/user.json\",\n",
        "  verbose=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10008"
      },
      "source": [
        "#3. Enter CM360 Data Transfer To Bigquery Recipe Parameters\n",
        " 1. Ensure your user has [access to the bucket](https://developers.google.com/doubleclick-advertisers/dtv2/getting-started).\n",
        " 1. Provide the DT bucket name to read from.\n",
        " 1. Provide the path of the files to read.\n",
        " 1. Each file is synchronized to a unique table.  Use a view or aggregate select.\n",
        "Modify the values below for your use case, can be done multiple times, then click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "397f08b10009"
      },
      "source": [
        "FIELDS = {\n",
        "  'auth_read':'user',  # Credentials used for reading data.\n",
        "  'auth_write':'service',  # Credentials used for writing data.\n",
        "  'bucket':'',  # Name of bucket where DT files are stored.\n",
        "  'paths':[],  # List of prefixes to pull specific DT files.\n",
        "  'days':2,  # Number of days back to synchronize.\n",
        "  'hours':0,  # Number of hours back to synchronize.\n",
        "  'dataset':'',  # Existing dataset in BigQuery.\n",
        "}\n",
        "\n",
        "print(\"Parameters Set To: %s\" % FIELDS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f08b10010"
      },
      "source": [
        "#4. Execute CM360 Data Transfer To Bigquery\n",
        "This does NOT need to be modified unless you are changing the recipe, click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "397f08b10011"
      },
      "source": [
        "from starthinker.util.configuration import execute\n",
        "from starthinker.util.recipe import json_set_fields\n",
        "\n",
        "TASKS = [\n",
        "  {\n",
        "    'dt':{\n",
        "      'auth':{'field':{'name':'auth_read','kind':'authentication','order':0,'default':'user','description':'Credentials used for reading data.'}},\n",
        "      'from':{\n",
        "        'bucket':{'field':{'name':'bucket','kind':'string','order':2,'default':'','description':'Name of bucket where DT files are stored.'}},\n",
        "        'paths':{'field':{'name':'paths','kind':'string_list','order':3,'default':[],'description':'List of prefixes to pull specific DT files.'}},\n",
        "        'days':{'field':{'name':'days','kind':'integer','order':4,'default':2,'description':'Number of days back to synchronize.'}},\n",
        "        'hours':{'field':{'name':'hours','kind':'integer','order':5,'default':0,'description':'Number of hours back to synchronize.'}}\n",
        "      },\n",
        "      'to':{\n",
        "        'auth':{'field':{'name':'auth_write','kind':'authentication','order':1,'default':'service','description':'Credentials used for writing data.'}},\n",
        "        'dataset':{'field':{'name':'dataset','kind':'string','order':6,'default':'','description':'Existing dataset in BigQuery.'}}\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "]\n",
        "\n",
        "json_set_fields(TASKS, FIELDS)\n",
        "\n",
        "execute(CONFIG, TASKS, force=True)\n"
      ]
    }
  ]
}
